> [광주 인공지능 사관학교 || 머신러닝의 분류](http://precourse.gj-aischool.com/lectures/8)

> "머신러닝은 데이터를 이해하는 알고리즘의 과학이자 하나의 어플리케이션이다"

인공지능 > 머신러닝 : 데이터에서 지식을 추출하여 가까운 미래를 예측하는 self-learning 알고리즘과 관련된 인공지능의 하위분야로 머신러닝이 출현. 
이전에 인간이 직접 대량의 데이터를 분석하고, 규칙을 유도하며 모델을 구축하는 기호 주의 방식에서 벗어나 머신러닝을 통해 성능 및 효율성을 포함한 모든 부분에서 점진적으로 성장할 수 있었음.

머신러닝은 크게
* 지도학습
* 비지도학습
* 강화학습

으로 분류된다.

1. 지도학습 : **레이블된 훈련 데이터를 활용하여** 모델을 학습시켜, 본적 없는 가까운 미래 데이터에 대해 예측값을 출력하는 것
	* 분류(Classification) : 개별 클래스 레이블이 있는 지도학습. 
	클래스를 구분하는 경계를 결정 경계(Decision boundery 라고 부름)
	ex : 손글씨 인식
	* 회귀 (Regression) : 연속적인 출력값을 예측하는 지도학습
	ex : 게임 랭크 점수 예측

2. 강화학습 : **환경이란 개념과 상호작용하며 에이전트의 성능을 향상**
![머신러닝](https://raw.githubusercontent.com/Deplim/DevNote/master/Image/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D.PNG)
환경의 현재 상태 정보는 보상 신호를 포함한다.
이 보상 함수를 통해 에이전트가 취한 행동에 대한 피드백을 준다.

이 상호작용이 반복되며 에이전트는 보상이 최대화되는 일련을 행동을 학습한다.

* Deep-Q-Learning

3. 비지도학습 : 지도학습에서는 데이터에 대해 사전에 옳은 답이 있고, 강화학습에서는 에이전트에 대한 보상방법이 있다. 
하지만 비지도학습에서는 **레이블되지 않거나 구조를 알 수 없는** 데이터를 다루며, 거기서 의미있는 정보 추출. 
	* 군집 : 사전 정보 없이 쌓여 있는 그룹 정보를 의미 있는 서브 그룹 또는 클러스터로 조직하는 탐색적 데이터 분석 기법
	* 차원 축소 : 고차원의 데이터를 저차원으로 축소.
	고차원의 데이터를 다룰 때 머신러닝 알고리즘의 계산 성능과 저장 공간의 한계를 극복하기 위함임. 
차원 축소 기법은 대부분의 정보를 유지하면서 더 작은 차원의 부분 공간으로 데이터를 압축.
