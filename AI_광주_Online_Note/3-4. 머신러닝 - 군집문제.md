> [광주 인공지능 사관학교 | 머신러닝 - 군집 문제]http://precourse.gj-aischool.com/lectures/10)

### 군집분석

비지도학습은 학습을 시켜줄 클래스 레이블이 없는 상태에서 학습 진행

* 군집분석은 클래스 레이블이 없는 데이터를 특정 군집으로 묶고자 할 떄 활용

--------------------------

* **K - 평균 (k-means)**

* 학계와 산업현장을 가리지 않고 사용됨

* 매우 쉬운 구현성

* 높은 계산 효율성

* 클러스터 중첩 x

* 계층적 x

* 클러스터당 하나 이상의 데이터

* 최적화 문제 종류임

* "프로토타입 기반 군집"(각 클러스터가 하나의 프로토타입으로 표현)에 속함.

* 프로토타입(prototype)

* 연속적인 특성에서는 비슷한 데이터 포인트의 센트로이드 (centroid - 평균)

* 범주형 특성에서는 메도이드 (medoid - 가장 자주 등장하는 포인트)

* 원형 클러스터를 구분하는데는 뛰어나지만, knn 알고리즘과 마찬가지로 사전에 몇개의 클러스터를 만들지 지정한 값에 따라 성능차이가 크게 남

* 랜덤 데이터 생성

![랜덤 데이터 생성](https://github.com/Deplim/DevNote/blob/master/Image/%EB%A0%8C%EB%8D%A4%20%EB%8D%B0%EC%9D%B4%ED%84%B0%20%EC%83%9D%EC%84%B1.PNG?raw=true)

* 이론

* **특성의 유사도** 에 기초하여 데이터들을 그룹으로 모음

* k- 평균 4단계 알고리즘

1. 데이터 포인트에서 랜덤하게 k개의 센트로이드를 초기 클러스터 중심으로 선택

2. 각 데이터를 가장 가까운 센트로이드에 할당

3. 할당된 샘플들의 중심으로 센트로이드를 이동

4. 클러스터 할당이 변하지 않거나, 사용자가 지정한 허용오차나, 최대 반복횟수에 도달할 때 까지 두번째와 세번째 과정을 반복

* 허용오차 - 오차 제곱합(SSE)  ![k - 평균](https://github.com/Deplim/DevNote/blob/master/Image/k%20%ED%8F%89%EA%B7%A0.PNG?raw=true)

* 유사도 기준

일반적으로 임의의 차원공간에 있는 두 요소 사이 유클리디안 거리, 혹은 유클리디안 거리 제곱 지표를 사용

* "왜곡" 을 줄이고자, 거리 산출시 불필요한 항목간의 특성을 제거하고 단위를 일치시키는 표준화 과정을 진행하면 더 좋은 결과를 가져올 수 있음.

* k 평균에서 고차원 데이터를 다루면 임의로 k 값을 할당했을때 좋은 성능을 보이는지 시각적으로 확인할 수가 없다.

* 구현 : 파이썬 사이킷런 라이브러리 사용

------------------------

* **k-means++**

초기 센트로이드를 좀더 효율적으로 할당

* 초기 센트로이드가 서로 멀리 떨어지도록 배치한다.

* 비지도학습에서는 결과가 나와도 지도학습에서 처럼 그것이 올바른 정답인지 확인할 수 있는 평가기법이 없다.

* 따라서 군집 품질을 평가해야하는 경우, 알고리즘 자체의 지표를 사용해야 함.

* k 평균 에서의 오차 제곱합

* **엘보우 방법(Elbow Method)**

최적인 클러스터 갯수 K 추정

![엘보우 방법](https://github.com/Deplim/DevNote/blob/master/Image/%EC%97%98%EB%B3%B4%EC%9A%B0%20%EB%B0%A9%EB%B2%95.PNG?raw=true)

* 왜곡이 빠르게 증가하는 지점의 K 값을 탐색

* **실루엣 그래프(silhouette analysis)**

클러스터 내 데이터들이 얼마나 조밀하게 모여있는지를 측정하는 그래프 도구  ![실루엣 그래프](https://github.com/Deplim/DevNote/blob/master/Image/%EC%8B%A4%EB%A3%A8%EC%97%A3%20%EA%B7%B8%EB%9E%98%ED%94%84.PNG?raw=true)

* k mean 이외에 다른 군집 알고리즘에도 적용 가능

----------------------

* **계층 군집**

* 덴드로그램 : 의미 있는 분류 체계를 만들어 군집 결과를 이해하는데 도움을 준다.

* 클러스터 갯수를 미리 지정하지 않아도 된다.

1. 병합 계층 군집 : 하나의 클러스터에서 시작해, 클러스터 속 데이터가 하나가 남을 때까지 반복적으로 클러스터를 나눈다.

* 단일 연결 : 클러스터 쌍에서 가장 비슷한, 가장 가까운 데이터 간의 거리를 계산해서 가장 작은 경우에 합침

* 완전 연결 : 클러스터 쌍에서 가장 먼 데이터 간의 거리 기준

* 평균 연결 : 두 클러스터간 모든 샘플 간의 평균 거리 기준

* 와드 연결  : 두 군집이 합쳐졌을 떄의 제곱 오차합이 가장 작게 증가하는 것이 기준

2. 분할 계층 군집 : 클러스터당 하나의 데이터에서 시작하여, 모든 데이터가 하나의 클러스터에 속할 때까지 가장 가까운 클러스터를 병합해 나간다.

* 이론 (완전 연결 기준)

1. 모든 데이터의 거리행렬을 계산

2. 모든 데이터 포인트를 단일 클러스터로 표현

3. 가장 멀리 떨어진 데이터 간 거리에 기초하여 가장 가까운 두 클러스터 합침.

4. 유사도 행렬 업데이트

5. 하나의 클러스터가 남을 때 까지 2~4 단계 반복

--------------------------------

* **밀집도 기반 군집(DBSCAN)**
	* 원형 클러스터를 가정하지 않음
	* 데이터가 조밀하게 모인 지역에 몇가지 특정한 조건에 따라 클러스터 레이블을 할당
	
	* 밀집도 : 특정 반경(엡실론) 안에 있는 샘플의 개수(MinPts) 로 정의	![밀집도 기반 군집](https://github.com/Deplim/DevNote/blob/master/Image/%EB%B0%80%EC%A7%80%EB%8F%84%20%EA%B8%B0%EB%B0%98%20%EA%B5%B0%EC%A7%91.png?raw=true)
	* 중심점 (core point) : 어떠한 데이터의 특정 반경(epslion) 안에 있는 이웃점이 임의로 지정한 개수(MinPts) 이상일때
		* core point 가 있으면 그 점을 중심으로 군집이 되고, core point 가 서로 다른 core point 의 군집의 일부가 되면 하나의 군집으로 연결한다.
	* 경계점 (border point) : 특정 반경 이내에 MinPts 보다 이웃은 적지만, 다른 중심점의 반경 안에 있을때
	* 이상치 (noise point) : 점들을 할당하고 나서 그 어떠한 레이블에도 속하지 않는 모든 점들
	
	* 장점 : 
		1. 모든 데이터들을 꼭 클러스터에 할당하지 않아도 됨. 자연스럽게 이상치 구분 가능
		2. 원형 클러스터를 가정하지 않음.  복잡한 구조를 가진 데이터 셋을 구분하는데 좋음.
			
	* 차원의 저주 : 밀집도 기반 군집 역시 데이터의 특성이 늘어남에 따라 차원의 저주로 인한 역호과가 증가하게 된다. 
	하지만 차원의 저주 문제는, 밀집도 기반 군집분석에만 해당되는 문제가 아닌, 율리디안 거리 측정 방식을 사용하는 다른 군집 알고리즘에도 영향을 끼친다.
	* 차원의 저주 해결 방법 
		* 차원 축소
		* 표준화
	
	* 하이퍼파라미터 최적화 : 알고리즘으로 좋은 군집 결과를 만들기 위해서는 epslion, MinPts 를 잘 최적화시켜줘야 함.
	
	* 성공적인 군집을 위한 조건 : 하나의 알고리즘과 일정한 하이퍼 파라미터에 의존하지 말 것.
	* 적절한 거리지표의 선택
	* 도메인 지식을 갖추는 것
