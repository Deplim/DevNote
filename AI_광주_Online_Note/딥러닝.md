> [광주 인공지능 사관학교 || 딥러닝](http://precourse.gj-aischool.com/lectures/4)

머신러닝을 하기 위한 3가지
* 입력 데이터
* 예상 출력값
* 알고리즘 정확도 측정법 : 알고리즘이 현재 출력과 예상출력 사이의 차이를 측정하는데 필요. 알고리즘 작동 방식을 조정하는 피드백 신호로 사용됨. 

머신러닝이나 딥러닝은 입력 데이터의 유용한 "표현" 을 학습하는 것이다.

> '표현' 이란 : 데이터를 대표하게 하거나 데이터를 부호화 하기 위해 데이터를 색다르게 살펴보는 방법.

머신러닝 모델이란 : 입력 데이터에 대한 '적절한 표현'을 찾는 일, 즉 분류작업과 같이 현재 직면하고 있는 작업에 더 적합한 데이터 변환 방식을 찾는 일이라고도 할 수 있다. 
또한 머신러닝에서 학습이란 : 더 나은 표현을 자동으로 찾아내는 과정 이라고 할 수 있다.

---------------------

딥러닝이란 : 머신러닝의 특정 하위 분야로, 표현들을 점점 더 의미있게 만들어 가는 연속 계층들을 학습하게 하는 데 중점을 두고 데이터 표현을 학습하는 새로운 방법.

딥러닝에서 '딥' 이라는 문구는 '연속된 표현 층' 이라는 개념을 나타낸 약자이다.
이러한 계층적 표현은 '신경망' 이라고 부르는 모델을 통해 학습되며 교차, 반복, 결합 등 다양한 방식으로 구조화 되어 있다. 

'신경망' 개념은 신경 생물학에서 다루는 뉴런(신경세포) 개념에서 차용되었다. 

여기서 뉴런의 특징은 다음과 같다.
1. 네트워크를 형성한다.
2. 여러 뉴런에 전달되는 신호의 합이 일정크기(임곗값) 을 넘지 않으면 뉴런은 전혀 반응하지 않는다.
3. 여러 뉴런에 전달되는 신호의 합이 일정 크기 임곗값을 넘으면 뉴런이 반응하며, 다른 뉴런에 일정 강도의 신호를 전달한다.
4. 2와 3에서 여러 뉴런에 전달되는 신호의 합은 신호마다 가중치가 다르다.

이러한 뉴런의 작용을 수학적으로 추상화해 일정 단위의 인위적인 네트워크로 표현한 것이 신경망이다.

이러한 신경망 계층을 다양한 방식으로 연속되게 구조화 한 방식이 딥러닝이라 할 수 있다.

#### 딥러닝 학습 방법

입력 데이터가 어떤 계층에 의해 변환되어 특정화 되면, 그 계층의 '가중치' 라는 형태로 저장된다. 
* 실제 가중치 형식은 여러 값들의 집합.

이후 다양한 계층들을 반복적으로 통과하며 학습을 진행한다.

여기서 '학습' 은 모든 계층의 가중치에 대한 값 집합을 찾아 새로운 입력값이 목표한 값에 올바르게 도달할 수 있도록 가중치를 조절하는 반복작업이다.
 
그러나 심층 신경망에서는 무수히 많은 가중치가 존재하는데 어떻게 모든 가중치들을 대상으로 올바른 값을 찾는가 ?

우선 신경망의 출력을 제어하려면 실제 출력 데이터와 신경망 출력층의 차이를 측정할 수 있어야 하는데 그 방법의 하나로 '목적함수' 라는 개념이 있다.

'목적함수' 란 신경망의 손실함수(loss function)이다.  손실함수는 실제 결과값과 신경망이 예측한 결과값을 가지고 거리 점수를 계산하여 이 특정 사례에서 신경망이 얼마나 잘 수행되었는지 계산해 낸다. 

딥러닝에서는 이 점수를 피드백 신호로 사용해 현재 사례의 손실 점수를 낮추는 방향으로 무작위 가중치값들을 조금씩 조절해 나간다.

이러한 조절 방식은 주로 역전파 알고리즘을 통해 구현된다.

딥러닝은 머신러닝 하위 분야로 꽤 오래전이 등장했지만 2010년대가 되서야 주목받기 시작했다. 이후 많은 성과를 이뤘으며, 특히 지각 문제와 관련해 놀라운 성과를 이뤘으며, 오랬동안 머신러닝으로 풀기 어려웠던 분야에서 획기적인 발전을 이뤘다. 
